---
output:
  pdf_document: default
  html_document: default
---
Data Generation process for our models

```{r}
set.seed(2020)

n <- 250  # sample size

x1 <- rnorm(n)
x2 <- rnorm(n)
x3 <- rnorm(n)
x4 <- rbinom(n, 1, 0.5)
x5 <- sample(1:3, n, replace = TRUE)
```

```{r}
#g function like they describe
g_func <- function(x) {
  return(ifelse(x == 1, 2, ifelse(x == 2, -1, -4)))
}
```

```{r}
#Get mu
mu_linear <- 1 + g_func(x4) + x1 * x3
mu_nonlinear <- -6 + g_func(x4) + 6 * abs(x3 - 1)
```

```{r}
#Get tau
tau_homogeneous <- rep(3, n)
tau_heterogeneous <- 1 + 2 * x2 * x5
```

```{r}
#Get the propensity score
ui <- runif(n)
s_linear <- sd(mu_linear)
s_nonlinear <- sd(mu_nonlinear)

# Standard normal CDF
phi <- pnorm

# Propensity scores
pi_linear <- 0.8 * phi(3 * mu_linear / s_linear - 0.5 * x1) + 0.05 + ui / 10
pi_nonlinear <- 0.8 * phi(3 * mu_nonlinear / s_nonlinear - 0.5 * x1) + 0.05 + ui / 10
```

```{r}
#Simulate Treatment assignments
Z_linear <- rbinom(n, 1, pi_linear)
Z_nonlinear <- rbinom(n, 1, pi_nonlinear)

# error term
epsilon <- rnorm(n)
```

```{r}
#Now lets get our outcomes according to this formula: Y = mu + tau * Z + rnorm(n)
#Create the 4 datasets
#Linear and homogeneous
Y_lin_hom <- mu_linear + tau_homogeneous * Z_linear + epsilon

#Linear heterogeneous
Y_lin_het <- mu_linear + tau_heterogeneous * Z_linear + epsilon

#Non-linear homogeneous
Y_nonlin_hom <- mu_nonlinear + tau_homogeneous * Z_nonlinear + epsilon

#Non-linear heterogeneous
Y_nonlin_het <- mu_nonlinear + tau_heterogeneous * Z_nonlinear + epsilon
```

```{r}
#Throw these bad boys into a dataframes
data_lin_hom <- data.frame(Y = Y_lin_hom, Z = Z_linear, x1, x2, x3, x4, x5)
data_lin_het <- data.frame(Y = Y_lin_het, Z = Z_linear, x1, x2, x3, x4, x5)
data_nonlin_hom <- data.frame(Y = Y_nonlin_hom, Z = Z_nonlinear, x1, x2, x3, x4, x5)
data_nonlin_het <- data.frame(Y = Y_nonlin_het, Z = Z_nonlinear, x1, x2, x3, x4, x5)
```

```{r}
#Check those dataframes out
print(data_lin_hom)
print(data_lin_het)
print(data_nonlin_hom)
print(data_nonlin_het)
```


```{r}
library(bcf)
library(dplyr)

set.seed(2020)

# Setup
n <- 250
simulations <- 50
X <- data.frame(x1, x2, x3, x4, x5)
X_mat <- as.matrix(X)

# Define all 4 DGP combinations
dgp_configs <- list(
  list(mu = mu_linear, tau = tau_homogeneous, Z = Z_linear, pihat = pi_linear, label = "linear_mu_homog_tau"),
  list(mu = mu_linear, tau = tau_heterogeneous, Z = Z_linear, pihat = pi_linear, label = "linear_mu_heterog_tau"),
  list(mu = mu_nonlinear, tau = tau_homogeneous, Z = Z_nonlinear, pihat = pi_nonlinear, label = "nonlinear_mu_homog_tau"),
  list(mu = mu_nonlinear, tau = tau_heterogeneous, Z = Z_nonlinear, pihat = pi_nonlinear, label = "nonlinear_mu_heterog_tau")
)

# Storage for all results
all_results <- data.frame()

# Loop through each DGP setup
for (config in dgp_configs) {
  mu <- config$mu
  tau <- config$tau
  Z <- config$Z
  pihat <- config$pihat
  label <- config$label

  true_ATE <- mean(tau)
  true_CATE <- tau

  rmse_results <- data.frame(
    ATE_RMSE = numeric(simulations),
    CATE_RMSE = numeric(simulations)
  )

  for (i in 1:simulations) {
    # Generate new error term for each simulation
    epsilon <- rnorm(n)
    Y <- mu + tau * Z + epsilon

    # Fit BCF model with the correct propensity scores for this DGP
    fit <- bcf(y = Y, z = Z, x_control = X_mat, x_moderate = X_mat, pihat = pihat,
              nburn = 1000, nsim = 2000, nthin = 2, 
              ntree_control = 200, ntree_moderate = 50, 
              update_interval = 100)
    
    # Extract posterior mean of treatment effects
    tau_hat <- rowMeans(fit$tau)

    # Calculate RMSEs
    rmse_results$ATE_RMSE[i] <- sqrt((mean(tau_hat) - true_ATE)^2)
    rmse_results$CATE_RMSE[i] <- sqrt(mean((tau_hat - true_CATE)^2))
  }

  # Summarize results for this DGP
  summary_rmse <- rmse_results %>%
    summarise(
      ATE_RMSE = mean(ATE_RMSE),
      CATE_RMSE = mean(CATE_RMSE)
    ) %>%
    mutate(DGP = label)

  all_results <- bind_rows(all_results, summary_rmse)
}

# Show all results
print(all_results)
```

```{r}
install.packages('bartCause')
library(bartCause)


set.seed(2020)

# List of datasets
data_list <- list(
  lin_hom = data_lin_hom,
  lin_het = data_lin_het,
  nonlin_hom = data_nonlin_hom,
  nonlin_het = data_nonlin_het
)

# True CATEs for each dataset
true_tau_list <- list(
  lin_hom = tau_homogeneous,
  lin_het = tau_heterogeneous,
  nonlin_hom = tau_homogeneous,
  nonlin_het = tau_heterogeneous
)

results <- data.frame(
  dataset = character(),
  ATE_RMSE = numeric(),
  CATE_RMSE = numeric()
)

for (data_name in names(data_list)) {
  data <- data_list[[data_name]]
  true_tau <- true_tau_list[[data_name]]
  true_ATE <- mean(true_tau)
  n <- nrow(data)
  X <- data[, c("x1", "x2", "x3", "x4", "x5")]
  Z <- data$Z
  mu <- data$Y - true_tau * Z  # to regenerate Y with noise later

  # Storage
  ate_rmse <- numeric(50)
  cate_rmse <- numeric(50)

  for (i in 1:50) {
    epsilon <- rnorm(n)
    Y_sim <- mu + true_tau * Z + epsilon

    # Estimate propensity scores
    ps_model <- glm(Z ~ ., data = cbind(Z, X), family = binomial)
    pihat <- predict(ps_model, type = "response")

    # Fit BART using bartCause
    bart_fit <- bartc(
      response = Y_sim,
      treatment = Z,
      confounders = X,
      method.rsp = "bart",
      method.trt = "bart",  
      estimand = "ate",
      commonSup.rule = "none",
      p.score = pihat,
      p.scoreAsCovariate = TRUE
    )

    cate_hat <- fitted(bart_fit, type = "cate")
    ate_hat <- mean(cate_hat)

    # Store RMSEs
    ate_rmse[i] <- sqrt((ate_hat - true_ATE)^2)
    cate_rmse[i] <- sqrt(mean((cate_hat - true_tau)^2))
  }

  # Save results
  results <- rbind(results, data.frame(
    dataset = data_name,
    ATE_RMSE = mean(ate_rmse),
    CATE_RMSE = mean(cate_rmse)
  ))
}

print(results)
```



 
